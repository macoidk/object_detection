{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42921317",
   "metadata": {},
   "source": "### Set up model and define necessary stuff"
  },
  {
   "cell_type": "code",
   "id": "0d9d67d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T15:59:20.765621Z",
     "start_time": "2025-01-31T15:59:15.730647Z"
    }
   },
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "import torch\n",
    "from models.centernet import ModelBuilder\n",
    "from data.dataset import Dataset\n",
    "from torch.utils.data import Subset\n",
    "from postprocess_visual.object_detection_visualizer import (\n",
    "    ObjectDetectionVisualizer,\n",
    ")\n",
    "from utils.load_model import load_model\n",
    "from utils.predictions import get_predictions\n",
    "\n",
    "\n",
    "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def transform_dataset(dataset):\n",
    "    \"\"\"Transform the dataset for visualization\"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(256, 256)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return Dataset(dataset=dataset, transformation=transform)\n",
    "\n",
    "\n",
    "model = load_model(Device, ModelBuilder, alpha=0.25)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_dict = {}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get predictions for defined dataset",
   "id": "68bfeb2f53db37a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_dataset():\n",
    "    # Load VOC dataset\n",
    "    dataset_val = torchvision.datasets.VOCDetection(\n",
    "        root=\"../VOC\", year=\"2007\", image_set=\"train\", download=False\n",
    "    )\n",
    "    dataset_val = torchvision.datasets.wrap_dataset_for_transforms_v2(dataset_val)\n",
    "\n",
    "    # Define a dataset that is a subset of the initial dataset\n",
    "    indices = range(10)\n",
    "    dataset_val = Subset(dataset_val, indices)\n",
    "\n",
    "    return dataset_val\n",
    "\n",
    "\n",
    "dataset = prepare_dataset()\n",
    "\n",
    "# Transform the dataset to the correct form for further processing\n",
    "dataset_transformed = transform_dataset(dataset)\n",
    "\n",
    "# Get predictions\n",
    "predictions = get_predictions(Device, model, dataset_transformed)"
   ],
   "id": "7ecc6696a43d9415",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91a9586f",
   "metadata": {},
   "source": "### Predictions visualization"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create visualizer with default settings\n",
    "visualizer = ObjectDetectionVisualizer(\n",
    "    dataset=dataset_transformed,\n",
    "    input_height=256,\n",
    "    input_width=256,\n",
    "    confidence_threshold=0.3,\n",
    ")\n",
    "\n",
    "# Visualize predictions\n",
    "visualizer.visualize_predictions(predictions)"
   ],
   "id": "b64c81a7d8d163eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42ea5ad103d5227a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
